---
title: "EPILOG"
date: 2020-12-19
---

**BAIN?!** 

Die Dozierenden und IT-Berater Felix Lohmeier und Sebastian Meyer haben im Kurs das Handwerkszeug für die IT in Bibliotheken und Archiven praxisnah vermittelt. Wir haben diverse praktische Übungen ausgeführt und Einblick in verschiedene Bibliotheks- und Archivinformationssysteme erhalten. Während ich im Prolog die vorgegebenen Lernziele aufgelistet und meine Erwartungen formuliert habe, gilt es hier im Epilog die Lerninhalte und mein Vorgehen bei der Erstellung der Blogbeiträge zu reflektieren.

## Wurden die Lernziele erfüllt?
- **Funktionsweise spezifischer Bibliotheks- und Archivsoftware verstehen** > [Beitrag 2](https://kkbuhler.github.io/BAIN/2020/09/25/tag2.html) und [Beitrag 4](https://kkbuhler.github.io/BAIN/2020/10/09/tag4.html) 
- **richtige Software für eine spezifische Aufgabe evaluieren** > Wir haben keine Software-Produkte evaluiert - aber in fast jeder Vorlesung einen spezifischen Anwendungsbereich und die Software dazu kennengelernt.
- **Suchmaschinen konfigurieren** > [Beitrag 9](https://kkbuhler.github.io/BAIN/2020/12/11/tag9.html)
- **Bibliothekarische und archivarische Metadaten modellieren und diese mit entsprechenden Protokollen / Anwendungen übertragen** > [Beitrag 8](https://kkbuhler.github.io/BAIN/2020/11/27/tag8.html)
- **Crosswalks zwischen unterschiedlichen Metadatenformaten programmieren** > Wir haben keine Crosswalks programmiert, wir haben diese einfach durchgeführt: [Beitrag 7](https://kkbuhler.github.io/BAIN/2020/11/20/tag7.html)

## Wurden meine Erwartungen an den Kurs erfüllt?
Wohlweislich habe ich meinen Fokus für diesen Blog bereits von Beginn an weniger auf Ausführungen zu technischen Finessen gelegt, sondern auf die inhaltlichen Zusammenhänge. Dies hat mir erlaubt, den recht technisch ausgelegten Kurs auf einer Metaebene zu behandeln und dadurch Erkenntnisse über das grobe Ganze hinweg zu generieren. Gerade auch durch die vielleicht simpel anmutenden Fragestellungen war ich gefordert, den Sachverhalt gründlich und grundsätzlich zu erörtern. Weiter hat mich dieses Vorgehen auch krisenfrei durch den Kurs geführt, weil ich mich bei Misserfolgen bei Fehlinstallationen, der Fehlersuche in einem Code oder der Eingabe von kryptischen Befehlen nicht unter Druck gesetzt fühlte. 
Weiter war mir als Anwenderin des Bibliotheksinformationssystem ALEPH und des Archivinformationssystem AtoM bereits ein Praxisbezug gegeben. Im Arbeitsalltag wird die Software allerdings nur sehr eingeschränkt benutzt. Ich fand es deshalb sehr interessant, über den kleinen Anwendungsbereich hinaus die Funktionsweise solcher Informationsysteme zu erfahren. 
Die Hoffnung, in diesem Kurs auch [kleio](https://kleio.com) näher zu betrachten, blieb unerfüllt. Stattdessen habe ich mich in ANTON vertieft. (vgl. [Beitrag 5](https://kkbuhler.github.io/BAIN/2020/10/16/tag5.html))
Manchmal formulieren Lernziele auch Befürchtungen: "Suchmaschine konfigurieren, Metadaten modellieren und Crosswalks programmieren" - Halleluja, das kann ja heiter werden! Für diese technischen Anteile der Beschreibung bringe ich wenig/kein Know How mit. Für jene Klassenkolleg'innen mit Vertiefung «Web und Usability Engineering» mag das ein Vergnügen sein, weniger aber für mich. Entsprechend dürfte Sebastian Meyer mein enger Gefährte werden. ;)


BEST PRACTICE:
Deutsches Literaturarchiv Marbach
In Arbeit. 
iterative Verbesserungen. Im Rahmen eines Change Management Prozesses durchführen. Mitarbeiterperspektive verstehen. Soziales und Kommunikation nicht unterschätzen. >> Folien
Datenbereinigung. Verschiedene Datenbestände export und mit OpenRefine modelliert, gemeinsamer Suchindex abgeglichen. Zielformat: CSV
Datensuche im Suchindex und in Normdaten möglich. Kombinationen sind möglich. 
SolR wurde als Suchindex verwendet. Automatisches Ergänzen in der Suche: Wie müsste Anfrage in SolR lauten?
LinkData simulieren. 
Ranking: je mehr Resourcen mit einer Normdatei verbunden sind, desto höher erscheint sie im Ranking
"Typo3Find" mit Suchoberfläche für Typo3.  
Metadatenformat: Archivmaterial und Bücher, eigenes System angewendet aufgrund der vorgegebenen Feldern
aus dem System gegeben, daraus Suchindex angelegt und Facetten zugeordnet.
Nach Rollen (Schlagworten) durchsuchbar.

Wikidata abfragen, um weitere externe Information mit den eigenen 4'000'000 Datensätze verknüpft.
Über Nacht per OpenRefine in Cache gespeichert und dann Datensätze angereichert

Bei Entwicklung sind Nutzerinnen wichtig. Personas erstellen.
Implementierung dauerte insgesamt 4 Jahre. Vorprojekt mit Pilot, verschiedene Partner im Spiel.
effective webwork (grafische Gestaltung)
Online 1. Quartal 2021

Der alte Katalog war der in aDIS/BMS integrierte OPAC, ja. Hier kann der alte Katalog ausprobiert werden: https://www.dla-marbach.de/katalog/

## Meine Erkenntnisse 
**Lerntagebuch als lehrreicher Leistungsnachweis:** Durch das Reflektieren der Lehreinheiten in Form des Lerntagebuchs wurden die Inhalte individuell vertieft. Dass der Schwerpunkt zur durchgeführten Lehrveranstaltung für den Beitrag selber definiert werden konnte, habe ich sehr geschätzt. Mich hat das motiviert, Fragen zu stellen und diese auch in manchmal ausführlichen Recherchen zu beantworten.

**Fragestellungen für Erkenntnisgewinn:** Alleine schon das Überlegen der Frage brachte mich dem Kern der Sache oft ein schönes Stück näher. Durch das Fragen offenbarten sich mir Wissenslücken, die ich durch das Beantworten der Fragen zu füllen suchte. 

**Bibliografischen Metadaten aus Sicht der IT:** Als Anwenderin von Bibliotheks- und Archivinformationssystemen im Bereich der Katalogisierung von Medien war es interessant, eine technischen Einblick in die Kulissen hinter der Systeme zu werfen. Während die Bibliotheks- oder Archivangestellte in der Regel Metadaten durch einzelne Einträge in Felder oder die gezielte Vervielfältigung von Exemplarsätzen erstellt, sind in diesem Kurs Möglichkeiten der effizienten Bearbeitung und Übernahme von grossen Datenmengen aufgezeigt worden.

**Umgang mit grossen Datenmengen erfordert erweiterte Kenntnisse:** Vor allem das Manipulieren und Importieren von grossen Datenmengen in ein Informationssystem ist ein komplexer Vorgang, der die Anwendung verschiedener Befehle erfordert. Hier scheint mir persönlich der Einbezug einer Fachperson, z.B. Systembibliothekar'in oder Software-Dienstleiter'in, durchaus sinnvoll. Es ist wohl ohnehin nicht die Meinung dieser Lehrveranstaltung, dass alle Informationswissenschaftler'innen solche Aufgaben selber lösen sollen, sondern dass sie das die Zusammenhänge verstehen und bei der Kommunikation mit den Fachpersonen eine Ahnung haben. 

**Einsatz des Terminals:** Auch wenn der Nutzen des Terminals verheissungsvoll beschrieben wurde, so konnte ich mich doch nicht richtig damit anfreunden. Zu abstrakt ist mir die Anwendung. Visuelle Oberflächen sind mir lieber, weil sie mir das klitzekleine Gefühl vermitteln, eher zu wissen, was ich gerade tu'. Zudem werde ich in meinem Arbeitsumfeld selber keine Software installieren. Diese Aufgabe steht spezialisiertem Personal oder dazu beauftragen Fachpersonen zu. 


persönliche Erfahrungen schildern:
Wie war das persönliche Vorgehen (Abweichungen vom Skript)?
Wo gab es Schwierigkeiten? Was waren die Aha-Effekte?
Persönliche Stellungnahme zu den Inhalten ist ausdrücklich erwünscht.

## Zum Schluss, liebe Leser'in ...
... hoffe ich, dass ich mit meinen vielen Fragen und vor allem den Antworten dazu, auch dir einige Erkenntnisse bescheren konnte!




